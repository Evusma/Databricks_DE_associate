{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fad377d-af23-4453-b509-5a20d322ed9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Auto Loader with Pyspark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2641875f-3176-4126-87f4-d54e5c0e8eec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Set up of catalog and schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6252fa87-965d-4859-8f89-c64c72512e0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE CATALOG catalog\")\n",
    "spark.sql(\"USE schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "895c0cca-f351-4e7e-948d-62fbc0b6dd72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Set up of the data structure for the Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3cfe0e0-ddba-48b9-b9e4-db8c89a230f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "schema = StructType([\n",
    "   StructField(\"Id\", IntegerType(), True),\n",
    "   StructField(\"name\", StringType(), True),\n",
    "   StructField(\"age\", IntegerType(), True),\n",
    "   StructField(\"money\", IntegerType(), True),\n",
    "   StructField(\"sales\", IntegerType(), True),\n",
    "   StructField(\"units\", IntegerType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19c36aca-8901-46c5-8174-d60bc93edb3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Reading the csv which are already in the volume, and future csv files (by file arrival). \n",
    "\n",
    "Selecting the format **\"cloudFiles\"** we are setting up Auto Loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a27fa18d-8ba1-4f84-a431-3a962d9c3fbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (spark.readStream\n",
    "      .format(\"cloudFiles\")\n",
    "      .option(\"cloudFiles.format\", \"csv\")   # or csv, parquet, etc.\n",
    "      .option(\"header\", \"true\")\n",
    "      .schema(schema)  # Schema enforcement\n",
    "      .load(\"/Volumes/autoloader/csv/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fed09ef-400c-49b4-bb11-e61a918fc926",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Writing the data from the cvs to the Delta table. \n",
    "\n",
    "The checkpoint folder has the information for Auto Loader so it avoid reading and writing the same file more than once.\n",
    "\n",
    "Not need to create the Delta table before starting to load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3393ac30-198c-4ee2-9002-ccf3e414c533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.connect.streaming.query.StreamingQuery at 0x7f51990339b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.writeStream\n",
    "   .format(\"delta\")\n",
    "   .option(\"checkpointLocation\", \"/Volumes/autoloader/_checkpoints\")\n",
    "   .outputMode(\"append\")\n",
    "   # .trigger(processingTime='5 seconds')\n",
    "   .trigger(availableNow=True)\n",
    "   .table(\"autoloader\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b2f7885-cf13-4173-8a98-8804e241a2a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Checking that the data is well loaded in the Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e73fc2f-5c32-4cd3-b5e7-32764764d9c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>name</th><th>age</th><th>money</th><th>sales</th><th>units</th></tr></thead><tbody><tr><td>10</td><td>Julia</td><td>26</td><td>1300</td><td>2800</td><td>28</td></tr><tr><td>11</td><td>Kevin</td><td>39</td><td>1750</td><td>5500</td><td>55</td></tr><tr><td>12</td><td>Laura</td><td>31</td><td>1450</td><td>3800</td><td>38</td></tr><tr><td>7</td><td>George</td><td>30</td><td>1100</td><td>2200</td><td>22</td></tr><tr><td>8</td><td>Hannah</td><td>28</td><td>1600</td><td>4000</td><td>40</td></tr><tr><td>9</td><td>Ian</td><td>36</td><td>2000</td><td>6500</td><td>65</td></tr><tr><td>1</td><td>Alice</td><td>25</td><td>1200</td><td>4500</td><td>45</td></tr><tr><td>2</td><td>Bob</td><td>32</td><td>850</td><td>3000</td><td>30</td></tr><tr><td>3</td><td>Charlie</td><td>29</td><td>1500</td><td>6000</td><td>60</td></tr><tr><td>1</td><td>Alice</td><td>25</td><td>1200</td><td>4500</td><td>45</td></tr><tr><td>2</td><td>Bob</td><td>32</td><td>850</td><td>3000</td><td>30</td></tr><tr><td>3</td><td>Charlie</td><td>29</td><td>1500</td><td>6000</td><td>60</td></tr><tr><td>4</td><td>Diana</td><td>41</td><td>2100</td><td>7500</td><td>75</td></tr><tr><td>5</td><td>Ethan</td><td>27</td><td>950</td><td>2500</td><td>25</td></tr><tr><td>6</td><td>Fiona</td><td>34</td><td>1800</td><td>5000</td><td>50</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         10,
         "Julia",
         26,
         1300,
         2800,
         28
        ],
        [
         11,
         "Kevin",
         39,
         1750,
         5500,
         55
        ],
        [
         12,
         "Laura",
         31,
         1450,
         3800,
         38
        ],
        [
         7,
         "George",
         30,
         1100,
         2200,
         22
        ],
        [
         8,
         "Hannah",
         28,
         1600,
         4000,
         40
        ],
        [
         9,
         "Ian",
         36,
         2000,
         6500,
         65
        ],
        [
         1,
         "Alice",
         25,
         1200,
         4500,
         45
        ],
        [
         2,
         "Bob",
         32,
         850,
         3000,
         30
        ],
        [
         3,
         "Charlie",
         29,
         1500,
         6000,
         60
        ],
        [
         1,
         "Alice",
         25,
         1200,
         4500,
         45
        ],
        [
         2,
         "Bob",
         32,
         850,
         3000,
         30
        ],
        [
         3,
         "Charlie",
         29,
         1500,
         6000,
         60
        ],
        [
         4,
         "Diana",
         41,
         2100,
         7500,
         75
        ],
        [
         5,
         "Ethan",
         27,
         950,
         2500,
         25
        ],
        [
         6,
         "Fiona",
         34,
         1800,
         5000,
         50
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "age",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "money",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "sales",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "units",
            "nullable": true,
            "type": "integer"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 29
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "money",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "sales",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "units",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM autoloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b44b414-dd04-4f2a-ba31-3b3663b0041c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Checking the data of all csv files (path to the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb5cb6b3-fcea-4fbf-8d03-9f43fc5e032a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>name</th><th>age</th><th>money</th><th>sales</th><th>units</th><th>_rescued_data</th></tr></thead><tbody><tr><td>10</td><td>Julia</td><td>26</td><td>1300</td><td>2800</td><td>28</td><td>null</td></tr><tr><td>11</td><td>Kevin</td><td>39</td><td>1750</td><td>5500</td><td>55</td><td>null</td></tr><tr><td>12</td><td>Laura</td><td>31</td><td>1450</td><td>3800</td><td>38</td><td>null</td></tr><tr><td>7</td><td>George</td><td>30</td><td>1100</td><td>2200</td><td>22</td><td>null</td></tr><tr><td>8</td><td>Hannah</td><td>28</td><td>1600</td><td>4000</td><td>40</td><td>null</td></tr><tr><td>9</td><td>Ian</td><td>36</td><td>2000</td><td>6500</td><td>65</td><td>null</td></tr><tr><td>1</td><td>Alice</td><td>25</td><td>1200</td><td>4500</td><td>45</td><td>null</td></tr><tr><td>2</td><td>Bob</td><td>32</td><td>850</td><td>3000</td><td>30</td><td>null</td></tr><tr><td>3</td><td>Charlie</td><td>29</td><td>1500</td><td>6000</td><td>60</td><td>null</td></tr><tr><td>1</td><td>Alice</td><td>25</td><td>1200</td><td>4500</td><td>45</td><td>null</td></tr><tr><td>2</td><td>Bob</td><td>32</td><td>850</td><td>3000</td><td>30</td><td>null</td></tr><tr><td>3</td><td>Charlie</td><td>29</td><td>1500</td><td>6000</td><td>60</td><td>null</td></tr><tr><td>4</td><td>Diana</td><td>41</td><td>2100</td><td>7500</td><td>75</td><td>null</td></tr><tr><td>5</td><td>Ethan</td><td>27</td><td>950</td><td>2500</td><td>25</td><td>null</td></tr><tr><td>6</td><td>Fiona</td><td>34</td><td>1800</td><td>5000</td><td>50</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         10,
         "Julia",
         26,
         1300,
         2800,
         28,
         null
        ],
        [
         11,
         "Kevin",
         39,
         1750,
         5500,
         55,
         null
        ],
        [
         12,
         "Laura",
         31,
         1450,
         3800,
         38,
         null
        ],
        [
         7,
         "George",
         30,
         1100,
         2200,
         22,
         null
        ],
        [
         8,
         "Hannah",
         28,
         1600,
         4000,
         40,
         null
        ],
        [
         9,
         "Ian",
         36,
         2000,
         6500,
         65,
         null
        ],
        [
         1,
         "Alice",
         25,
         1200,
         4500,
         45,
         null
        ],
        [
         2,
         "Bob",
         32,
         850,
         3000,
         30,
         null
        ],
        [
         3,
         "Charlie",
         29,
         1500,
         6000,
         60,
         null
        ],
        [
         1,
         "Alice",
         25,
         1200,
         4500,
         45,
         null
        ],
        [
         2,
         "Bob",
         32,
         850,
         3000,
         30,
         null
        ],
        [
         3,
         "Charlie",
         29,
         1500,
         6000,
         60,
         null
        ],
        [
         4,
         "Diana",
         41,
         2100,
         7500,
         75,
         null
        ],
        [
         5,
         "Ethan",
         27,
         950,
         2500,
         25,
         null
        ],
        [
         6,
         "Fiona",
         34,
         1800,
         5000,
         50,
         null
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "age",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "money",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "sales",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "units",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "_rescued_data",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 46
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "money",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "sales",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "units",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM read_files(\n",
    "  '/Volumes/autoloader/csv/',\n",
    "  format => 'csv'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a646fb96-758a-4cf8-ae09-54d33f468ecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Reading the json which are already in the volume, and future json files (by file arrival). \n",
    "\n",
    "Selecting the format **\"cloudFiles\"** we are setting up Auto Loader.\n",
    "\n",
    "Writing the data from the json to the Delta table. \n",
    "\n",
    "The checkpoint folder has the information for Auto Loader so it avoid reading and writing the same file more than once.\n",
    "\n",
    "Not need to create the Delta table before starting to load data.\n",
    "\n",
    "Here, it is a Databricks extension to Spark Structured Streaming df.writeStream.table(\"autoloader_json\") This does not return a StreamingQuery. Instead, Databricks takes care of starting and managing the streaming query behind the scenes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "766f20f6-8445-4845-abdd-426ea7d318b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.connect.streaming.query.StreamingQuery at 0x7f47184437a0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (spark.readStream\n",
    "      .format(\"cloudFiles\")\n",
    "      .option(\"cloudFiles.format\", \"json\")   # or csv, parquet, etc.\n",
    "      .option(\"multiLine\", \"true\")  # this option is important if we want to read the json without problems\n",
    "      .schema(schema)\n",
    "      .load(\"/Volumes/autoloader/json/\"))\n",
    "\n",
    "\n",
    "(df.writeStream\n",
    "   .queryName(\"query_json\")\n",
    "   .format(\"delta\")\n",
    "   .option(\"checkpointLocation\", \"/Volumes/autoloader/_checkpoints_json\")\n",
    "   .outputMode(\"append\")\n",
    "   .table(\"autoloader_json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1901cd65-95a8-4948-a985-24c2874604b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We have a continuous running streaming Job. \n",
    "\n",
    "\n",
    "**To stop the stream**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e93132c1-ad56-41dc-9e2f-efb433420828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping query: <pyspark.sql.connect.streaming.query.StreamingQuery object at 0x7f4719515e20>\n"
     ]
    }
   ],
   "source": [
    "# option 1 (when we do not have .queryName(\"query_json\") on df.writeStream)\n",
    "for q in spark.streams.active:\n",
    "    print(f\"Stopping query: {q}\")\n",
    "    q.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b9ad060-9491-45f8-8da0-56070f3f47ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# option 1 (when we do have .queryName(\"query_json\") on df.writeStream)\n",
    "for q in spark.streams.active:\n",
    "    if q.name == \"query_json\":\n",
    "        q.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "185e6679-7b6e-440f-844b-3308ad206c40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Checking that the data is well loaded in the Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3e2d90-145f-4ec4-b716-da4cc4bdefb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>age</th><th>money</th><th>name</th><th>sales</th><th>units</th><th>_rescued_data</th><th>city</th></tr></thead><tbody><tr><td>10</td><td>26</td><td>1300</td><td>Julia</td><td>2800</td><td>28</td><td>null</td><td>null</td></tr><tr><td>11</td><td>39</td><td>1750</td><td>Kevin</td><td>5500</td><td>55</td><td>null</td><td>null</td></tr><tr><td>12</td><td>31</td><td>1450</td><td>Laura</td><td>3800</td><td>38</td><td>null</td><td>null</td></tr><tr><td>7</td><td>30</td><td>1100</td><td>George</td><td>2200</td><td>22</td><td>null</td><td>null</td></tr><tr><td>8</td><td>28</td><td>1600</td><td>Hannah</td><td>4000</td><td>40</td><td>null</td><td>null</td></tr><tr><td>9</td><td>36</td><td>2000</td><td>Ian</td><td>6500</td><td>65</td><td>null</td><td>null</td></tr><tr><td>1</td><td>25</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td><td>null</td><td>null</td></tr><tr><td>2</td><td>32</td><td>850</td><td>Bob</td><td>3000</td><td>30</td><td>null</td><td>null</td></tr><tr><td>3</td><td>29</td><td>1500</td><td>Charlie</td><td>6000</td><td>60</td><td>null</td><td>null</td></tr><tr><td>4</td><td>41</td><td>2100</td><td>Diana</td><td>7500</td><td>75</td><td>null</td><td>null</td></tr><tr><td>5</td><td>27</td><td>950</td><td>Ethan</td><td>2500</td><td>25</td><td>null</td><td>null</td></tr><tr><td>6</td><td>34</td><td>1800</td><td>Fiona</td><td>5000</td><td>50</td><td>null</td><td>null</td></tr><tr><td>1</td><td>25</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td><td>null</td><td>null</td></tr><tr><td>1</td><td>25</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td><td>null</td><td>Paris</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "10",
         "26",
         "1300",
         "Julia",
         "2800",
         "28",
         null,
         null
        ],
        [
         "11",
         "39",
         "1750",
         "Kevin",
         "5500",
         "55",
         null,
         null
        ],
        [
         "12",
         "31",
         "1450",
         "Laura",
         "3800",
         "38",
         null,
         null
        ],
        [
         "7",
         "30",
         "1100",
         "George",
         "2200",
         "22",
         null,
         null
        ],
        [
         "8",
         "28",
         "1600",
         "Hannah",
         "4000",
         "40",
         null,
         null
        ],
        [
         "9",
         "36",
         "2000",
         "Ian",
         "6500",
         "65",
         null,
         null
        ],
        [
         "1",
         "25",
         "1200",
         "Alice",
         "4500",
         "45",
         null,
         null
        ],
        [
         "2",
         "32",
         "850",
         "Bob",
         "3000",
         "30",
         null,
         null
        ],
        [
         "3",
         "29",
         "1500",
         "Charlie",
         "6000",
         "60",
         null,
         null
        ],
        [
         "4",
         "41",
         "2100",
         "Diana",
         "7500",
         "75",
         null,
         null
        ],
        [
         "5",
         "27",
         "950",
         "Ethan",
         "2500",
         "25",
         null,
         null
        ],
        [
         "6",
         "34",
         "1800",
         "Fiona",
         "5000",
         "50",
         null,
         null
        ],
        [
         "1",
         "25",
         "1200",
         "Alice",
         "4500",
         "45",
         null,
         null
        ],
        [
         "1",
         "25",
         "1200",
         "Alice",
         "4500",
         "45",
         null,
         "Paris"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Id",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "age",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "money",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "sales",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "units",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "_rescued_data",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "city",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 3
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "money",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sales",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "units",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM autoloader_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed76c747-14b8-49ef-a3e4-92c23694d539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Checking the data of all json files (path to the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91bd1573-06bd-470c-9b9c-862710ed4ec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>age</th><th>city</th><th>money</th><th>name</th><th>sales</th><th>units</th><th>_rescued_data</th></tr></thead><tbody><tr><td>10</td><td>26</td><td>null</td><td>1300</td><td>Julia</td><td>2800</td><td>28</td><td>null</td></tr><tr><td>11</td><td>39</td><td>null</td><td>1750</td><td>Kevin</td><td>5500</td><td>55</td><td>null</td></tr><tr><td>12</td><td>31</td><td>null</td><td>1450</td><td>Laura</td><td>3800</td><td>38</td><td>null</td></tr><tr><td>7</td><td>30</td><td>null</td><td>1100</td><td>George</td><td>2200</td><td>22</td><td>null</td></tr><tr><td>8</td><td>28</td><td>null</td><td>1600</td><td>Hannah</td><td>4000</td><td>40</td><td>null</td></tr><tr><td>9</td><td>36</td><td>null</td><td>2000</td><td>Ian</td><td>6500</td><td>65</td><td>null</td></tr><tr><td>1</td><td>25</td><td>null</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td><td>null</td></tr><tr><td>2</td><td>32</td><td>null</td><td>850</td><td>Bob</td><td>3000</td><td>30</td><td>null</td></tr><tr><td>3</td><td>29</td><td>null</td><td>1500</td><td>Charlie</td><td>6000</td><td>60</td><td>null</td></tr><tr><td>4</td><td>41</td><td>null</td><td>2100</td><td>Diana</td><td>7500</td><td>75</td><td>null</td></tr><tr><td>5</td><td>27</td><td>null</td><td>950</td><td>Ethan</td><td>2500</td><td>25</td><td>null</td></tr><tr><td>6</td><td>34</td><td>null</td><td>1800</td><td>Fiona</td><td>5000</td><td>50</td><td>null</td></tr><tr><td>1</td><td>25</td><td>Paris</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td><td>null</td></tr><tr><td>1</td><td>25</td><td>null</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td><td>null</td></tr><tr><td>1</td><td>25</td><td>null</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         10,
         26,
         null,
         1300,
         "Julia",
         2800,
         28,
         null
        ],
        [
         11,
         39,
         null,
         1750,
         "Kevin",
         5500,
         55,
         null
        ],
        [
         12,
         31,
         null,
         1450,
         "Laura",
         3800,
         38,
         null
        ],
        [
         7,
         30,
         null,
         1100,
         "George",
         2200,
         22,
         null
        ],
        [
         8,
         28,
         null,
         1600,
         "Hannah",
         4000,
         40,
         null
        ],
        [
         9,
         36,
         null,
         2000,
         "Ian",
         6500,
         65,
         null
        ],
        [
         1,
         25,
         null,
         1200,
         "Alice",
         4500,
         45,
         null
        ],
        [
         2,
         32,
         null,
         850,
         "Bob",
         3000,
         30,
         null
        ],
        [
         3,
         29,
         null,
         1500,
         "Charlie",
         6000,
         60,
         null
        ],
        [
         4,
         41,
         null,
         2100,
         "Diana",
         7500,
         75,
         null
        ],
        [
         5,
         27,
         null,
         950,
         "Ethan",
         2500,
         25,
         null
        ],
        [
         6,
         34,
         null,
         1800,
         "Fiona",
         5000,
         50,
         null
        ],
        [
         1,
         25,
         "Paris",
         1200,
         "Alice",
         4500,
         45,
         null
        ],
        [
         1,
         25,
         null,
         1200,
         "Alice",
         4500,
         45,
         null
        ],
        [
         1,
         25,
         null,
         1200,
         "Alice",
         4500,
         45,
         null
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "age",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "city",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "money",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "sales",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "units",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "_rescued_data",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 28
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "money",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sales",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "units",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "-- Option 1\n",
    "\n",
    "SELECT *\n",
    "FROM read_files(\n",
    "  '/Volumes/autoloader/json/',\n",
    "  format => 'json',\n",
    "  multiline => 'true'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cb639e9-20a3-47a9-9228-971c02b754ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>age</th><th>city</th><th>money</th><th>name</th><th>sales</th><th>units</th></tr></thead><tbody><tr><td>10</td><td>26</td><td>null</td><td>1300</td><td>Julia</td><td>2800</td><td>28</td></tr><tr><td>11</td><td>39</td><td>null</td><td>1750</td><td>Kevin</td><td>5500</td><td>55</td></tr><tr><td>12</td><td>31</td><td>null</td><td>1450</td><td>Laura</td><td>3800</td><td>38</td></tr><tr><td>7</td><td>30</td><td>null</td><td>1100</td><td>George</td><td>2200</td><td>22</td></tr><tr><td>8</td><td>28</td><td>null</td><td>1600</td><td>Hannah</td><td>4000</td><td>40</td></tr><tr><td>9</td><td>36</td><td>null</td><td>2000</td><td>Ian</td><td>6500</td><td>65</td></tr><tr><td>1</td><td>25</td><td>null</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td></tr><tr><td>2</td><td>32</td><td>null</td><td>850</td><td>Bob</td><td>3000</td><td>30</td></tr><tr><td>3</td><td>29</td><td>null</td><td>1500</td><td>Charlie</td><td>6000</td><td>60</td></tr><tr><td>4</td><td>41</td><td>null</td><td>2100</td><td>Diana</td><td>7500</td><td>75</td></tr><tr><td>5</td><td>27</td><td>null</td><td>950</td><td>Ethan</td><td>2500</td><td>25</td></tr><tr><td>6</td><td>34</td><td>null</td><td>1800</td><td>Fiona</td><td>5000</td><td>50</td></tr><tr><td>1</td><td>25</td><td>Paris</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td></tr><tr><td>1</td><td>25</td><td>null</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td></tr><tr><td>1</td><td>25</td><td>null</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         10,
         26,
         null,
         1300,
         "Julia",
         2800,
         28
        ],
        [
         11,
         39,
         null,
         1750,
         "Kevin",
         5500,
         55
        ],
        [
         12,
         31,
         null,
         1450,
         "Laura",
         3800,
         38
        ],
        [
         7,
         30,
         null,
         1100,
         "George",
         2200,
         22
        ],
        [
         8,
         28,
         null,
         1600,
         "Hannah",
         4000,
         40
        ],
        [
         9,
         36,
         null,
         2000,
         "Ian",
         6500,
         65
        ],
        [
         1,
         25,
         null,
         1200,
         "Alice",
         4500,
         45
        ],
        [
         2,
         32,
         null,
         850,
         "Bob",
         3000,
         30
        ],
        [
         3,
         29,
         null,
         1500,
         "Charlie",
         6000,
         60
        ],
        [
         4,
         41,
         null,
         2100,
         "Diana",
         7500,
         75
        ],
        [
         5,
         27,
         null,
         950,
         "Ethan",
         2500,
         25
        ],
        [
         6,
         34,
         null,
         1800,
         "Fiona",
         5000,
         50
        ],
        [
         1,
         25,
         "Paris",
         1200,
         "Alice",
         4500,
         45
        ],
        [
         1,
         25,
         null,
         1200,
         "Alice",
         4500,
         45
        ],
        [
         1,
         25,
         null,
         1200,
         "Alice",
         4500,
         45
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "age",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "city",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "money",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "sales",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "units",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 26
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "money",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sales",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "units",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "-- Option 2\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY VIEW multiLineJsonTable\n",
    "USING json\n",
    "OPTIONS (path=\"/Volumes/autoloader/json/\",multiline=true);\n",
    "\n",
    "select * from multiLineJsonTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6a41d05-4e81-45f8-b5dc-97ba964ff7e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In Spark Structured Streaming the DataFrame (df) itself has no stop() method, because the streaming query is managed through a StreamingQuery object, not the DataFrame. When you call df.writeStream...start(), Spark returns a StreamingQuery. You use that object to manage (stop, await termination, etc.) your continuous query.\n",
    "\n",
    "Here, the same code but with schema evolution and StreamingQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eac6f8c1-7266-41fc-a6bb-05eb7de41318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (spark.readStream\n",
    "      .format(\"cloudFiles\")\n",
    "      .option(\"cloudFiles.format\", \"json\")   # or csv, parquet, etc.\n",
    "      .option(\"multiLine\", \"true\")  # this option is important if we want to read the json without problems\n",
    "      .option(\"cloudFiles.schemaLocation\", \"/Volumes/autoloader/_schemas_json\")\n",
    "      .option(\"cloudFiles.schemaEvolutionMode\", \"addNewColumns\") \n",
    "      .load(\"/Volumes/autoloader/json/\"))\n",
    "\n",
    "\n",
    "query = (\n",
    "  df.writeStream\n",
    "   .format(\"delta\")\n",
    "   .option(\"checkpointLocation\", \"/Volumes/autoloader/_checkpoints_json\")\n",
    "   .option(\"mergeSchema\", \"true\")\n",
    "   .outputMode(\"append\")   \n",
    "   #.start(\"autoloader_json\"))  # for a delta table which exists already in the catalog\n",
    "   .toTable(\"autoloader_json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0bac7de-24a0-4ada-a452-1ab7716af321",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check if the stream is active\n",
    "query.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1e7dd7b-2b2b-475c-b589-a4971dde5654",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:132)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:132)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:473)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:750)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:84)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:84)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:84)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:84)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:728)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:911)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$4(Chauffeur.scala:937)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:936)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:991)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:776)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1033)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:953)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:548)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:513)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$13(ActivityContextFactory.scala:831)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:831)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:794)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:776)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:285)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:285)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:513)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:408)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:132)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:132)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:473)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:750)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:84)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:84)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:84)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:84)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:728)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:911)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$4(Chauffeur.scala:937)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:936)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:991)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:776)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1033)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:953)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:548)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:513)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$13(ActivityContextFactory.scala:831)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:831)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:794)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:776)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:285)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:285)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:513)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:408)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It makes your code wait until that the batch finishes (when we have the option df.writeStream.trigger(once=True) for exmple)\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79e865bc-d7ec-415a-af8c-3a627b46f9ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de93e044-b2ec-41b2-8c9b-1e3032cb9b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SQL\n",
    "\n",
    "Auto Loader, SQL code, is only used in Lakeflow Declarative Pipelines (Delta Life Tables)\n",
    "\n",
    "https://docs.databricks.com/aws/en/ingestion/cloud-object-storage/auto-loader/patterns?language=Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de4b3613-54e2-414d-9d1e-5a78139d0017",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REFRESH STREAMING TABLE autoloder_sql\n",
    "AS SELECT *\n",
    "FROM STREAM read_files(\n",
    "  '/Volumes/autoloader/json/',\n",
    "  format => 'json',\n",
    "  multiline => 'true'\n",
    ");\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0a79ef5-5002-40c9-ba63-47795e34264c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Batch-read data from json folder (spark.read =! spark.readStream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e7f0eb3-7202-4e81-9041-c4d8472573bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_json = (spark.read\n",
    "      .format(\"json\")\n",
    "      .option(\"multiLine\", True)\n",
    "      .load(\"/Volumes/autoloader/json/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bbfd19b-f09e-4f61-9eb7-cf14af69b230",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>age</th><th>money</th><th>name</th><th>sales</th><th>units</th></tr></thead><tbody><tr><td>10</td><td>26</td><td>1300</td><td>Julia</td><td>2800</td><td>28</td></tr><tr><td>11</td><td>39</td><td>1750</td><td>Kevin</td><td>5500</td><td>55</td></tr><tr><td>12</td><td>31</td><td>1450</td><td>Laura</td><td>3800</td><td>38</td></tr><tr><td>10</td><td>26</td><td>1300</td><td>Julia</td><td>2800</td><td>28</td></tr><tr><td>11</td><td>39</td><td>1750</td><td>Kevin</td><td>5500</td><td>55</td></tr><tr><td>12</td><td>31</td><td>1450</td><td>Laura</td><td>3800</td><td>38</td></tr><tr><td>7</td><td>30</td><td>1100</td><td>George</td><td>2200</td><td>22</td></tr><tr><td>8</td><td>28</td><td>1600</td><td>Hannah</td><td>4000</td><td>40</td></tr><tr><td>9</td><td>36</td><td>2000</td><td>Ian</td><td>6500</td><td>65</td></tr><tr><td>1</td><td>25</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td></tr><tr><td>2</td><td>32</td><td>850</td><td>Bob</td><td>3000</td><td>30</td></tr><tr><td>3</td><td>29</td><td>1500</td><td>Charlie</td><td>6000</td><td>60</td></tr><tr><td>4</td><td>41</td><td>2100</td><td>Diana</td><td>7500</td><td>75</td></tr><tr><td>5</td><td>27</td><td>950</td><td>Ethan</td><td>2500</td><td>25</td></tr><tr><td>6</td><td>34</td><td>1800</td><td>Fiona</td><td>5000</td><td>50</td></tr><tr><td>1</td><td>25</td><td>1200</td><td>Alice</td><td>4500</td><td>45</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         10,
         26,
         1300,
         "Julia",
         2800,
         28
        ],
        [
         11,
         39,
         1750,
         "Kevin",
         5500,
         55
        ],
        [
         12,
         31,
         1450,
         "Laura",
         3800,
         38
        ],
        [
         10,
         26,
         1300,
         "Julia",
         2800,
         28
        ],
        [
         11,
         39,
         1750,
         "Kevin",
         5500,
         55
        ],
        [
         12,
         31,
         1450,
         "Laura",
         3800,
         38
        ],
        [
         7,
         30,
         1100,
         "George",
         2200,
         22
        ],
        [
         8,
         28,
         1600,
         "Hannah",
         4000,
         40
        ],
        [
         9,
         36,
         2000,
         "Ian",
         6500,
         65
        ],
        [
         1,
         25,
         1200,
         "Alice",
         4500,
         45
        ],
        [
         2,
         32,
         850,
         "Bob",
         3000,
         30
        ],
        [
         3,
         29,
         1500,
         "Charlie",
         6000,
         60
        ],
        [
         4,
         41,
         2100,
         "Diana",
         7500,
         75
        ],
        [
         5,
         27,
         950,
         "Ethan",
         2500,
         25
        ],
        [
         6,
         34,
         1800,
         "Fiona",
         5000,
         50
        ],
        [
         1,
         25,
         1200,
         "Alice",
         4500,
         45
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "money",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sales",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "units",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_json)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7416509615163608,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Auto Loder tests 2025-09-25 12:02:17",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
